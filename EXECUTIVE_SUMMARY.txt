Executive Summary

OBJECTIVES. Employee recruiting and selection are those HR functions concerned with being able to foresee a current candidate's future on-the-job performance, their fit in the company and its culture and their overall tendency to stay in the company. Albeit this task seems like an inherent field for data scientists, there still are few data professionals within the field of HR. Main pitfalls are related to data protection and quality issues. In this project, for a client, I used competency measures of job candidates that were observed during their interviewing process, to predict the performance category they are likely to fall into after 6 months within the organisation.

The main goal here was to streamline the interviewing process by determining the best competencies to predict performance in a certain position. Furthermore, through heightened predictive validity of selection tools, the quality of the company's talent pool is thought to increase. A better interviewing process may therefore make any company more successful on the long run, while saving time and money.


METHODOLOGY. Due to data protection, the sample is a synthetic dataset that simulates the actual project sample's characteristics. In the real project, predictors were plentisome and contained sociodemographic data, work experience, and company-related data like line manager, etc. For confidentiality and better legibility of the notebooks, I decided to strongly simplify the predictor structure for this public version.

The sample comprises 225 customer service employees from a Peruvian healthcare company. In this version, a total of five competency measures and four potential measures have been chosen that were taken during the standardised interviewing process. Employee performance, the categorical, ordered target variable, was measured six months upon starting the role at the company. Its values are either "C" (average performer), "B" (fully meets expectations) and "A" (exceeds expectations). Ratings of performance were administered by the employees' line managers through a standardised, multi-faceted performance appraisal method, then aggregated into a single outcome measure.

I process data screening and cleaning as well as EDA before separating the data into train and test datasets. The train dataset is then pre-processed to address various shortcomings like skew and missing values, before fitting four different ML classifiers (NB, LDA, Random Forest, Non-Linear SVM) to the data using 10-fold repeated cross-validation (caret framework). Finally, all selected classifiers are used to predict performance outcomes of test data, and out-of-sample validity is observed to choose the model that best serves the project purpose.


RESULTS. Prior analyses of variable importance show that the five competency measures (namely 'quality awareness', 'service orientation', 'innovation', 'organisation' and 'problem-solving') are more highly related to the target variable then the potential measures ('curiosity', 'determination', 'analysis' and 'empowerment').

All four ML algorithms show significant improvement over a baseline model that just guesses the classes based on outcome class frequency. Out-of-sample Kappa metrics range from .48 (LDA) to .62 (RF). Additionally, some more performance differences can be observed between the four models. Similarly good results for Class A predictions are obtained with Naive Bayes and the non-linear SVM model (Class A F1 and Class A specificity values are .77 and .92, respectively, for both models). However, as on of the paramount objectives of the project was to make the interviewing process more efficient, Naive Bayes can be shown to be the model that fits best within the context as it only needed six of the nine predictors to render stable results (as opposed to all nine predictors used in the SVM model). Also, NB requires fewer computational resources, making it the best ML classifier candidate in this project.


IMPLICATIONS. This project provides new evidence of the predictive validity of ML algorithms for recruiting purposes. The main implications concern feature (= predictor) selection on the one hand, and the selection of appropiate algorithms on the other. Oftentimes, HR professionals put high esteem on the transparency and explicability of their decision-making. In this case, ML can be helpful to focus on the most predictive competencies or sections in the interviewing process. If transparency is of less concern, and more emphasis is laid on performance, ML might be used 'under the hood' to help make decisiones more objective and fair. 

In either of the two use cases mentioned above, it is very important to talk about adverse impact in the recruiting process. Any HR professional needs to understand that the underlying ML algorithm can only be as good as its data input; meaning that in general, an effort should be made by HR decision makers to standardise as much as possible the interviewing or any recruiting process, starting from CV screens, until the administration of psychometric testing, and the conduction and evaluation of job interviews or assessment centres. Bias (induced through socioeconomic status, sociodemographic information like gender or ethnicity, personal preferences, among many others) can happen at any moment of the recruiting process. It should therefore be reflected on thoroughly, and be mitigated by defining a) clear, observable behavioural anchors that make for a better or worse candidate and b) decision rules to before even the first candidate is assessed. 


ORIGINALITY. In this project, I try to reconcile two fields that are seemingly a good match, however in practice, have not been combined a lot as of now: standardised candidate assessment and data science. Although data science has been shown to be of value in numerous business function, it has so far focussed more on 'hard fact' fields like finance, production and so on. As HR thrives to become more strategic and data-driven, HR professionals are advised to seek quantitative evidence demonstrating their impact on the business. I do believe that data scientists can not only support this new development if they work hand in hand with HR, taking into consideration their vast domain knowledge and comprehension of 'soft business aspects'. Additionally, they could even train their understanding of the politics and ethics of data science. HR, in turn, may benefit from new insights and streamlining their processes as shown in the use case at hand.
